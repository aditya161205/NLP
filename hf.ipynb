{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAcjOzt0toji"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gZB0a_4jtrcy"
      },
      "outputs": [],
      "source": [
        "clf=pipeline('text-classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK_dbd4Ut46F"
      },
      "outputs": [],
      "source": [
        "text=\"i dont know how to operate hugging face \"\n",
        "\n",
        "output=clf(text)\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hebS4OHct_6p"
      },
      "outputs": [],
      "source": [
        "bot = pipeline(\"question-answering\")\n",
        "\n",
        "question=\"what do i dont know about hugging face?\"\n",
        "\n",
        "outputs=bot(question=question,context=text)\n",
        "\n",
        "pd.DataFrame([outputs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6PTQ-GJvocD"
      },
      "outputs": [],
      "source": [
        "text=\"Tokenization is easier on hugging face library\"\n",
        "\n",
        "tokenized=list(text)\n",
        "print(tokenized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqGJsudLPfES"
      },
      "outputs": [],
      "source": [
        "token2id={ch:idx for idx,ch in enumerate(sorted(set(tokenized)))}\n",
        "print(token2id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-XyXBKlRdy1"
      },
      "outputs": [],
      "source": [
        "input_id=[token2id[token] for token in tokenized]\n",
        "print(input_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a26aoj8sUm_S"
      },
      "outputs": [],
      "source": [
        "categorical_df=pd.DataFrame({\"Name\":[\"mumbai\",\"Delhi\",\"paris\"], \"labels\":[0,1,2]})\n",
        "print(categorical_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPO2LPZrWjjy"
      },
      "outputs": [],
      "source": [
        "pd.get_dummies(categorical_df['Name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GdJjXf7ZP6l"
      },
      "outputs": [],
      "source": [
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWhdWGHhWt_O"
      },
      "outputs": [],
      "source": [
        "\n",
        "input_id=torch.tensor(input_id)\n",
        "\n",
        "one_hot_id=torch.nn.functional.one_hot(input_id,num_classes=len(token2id))\n",
        "print(one_hot_id.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUIVRbmSYHer"
      },
      "outputs": [],
      "source": [
        "print(\"token:\", tokenized[0])\n",
        "print(\"token id:\", input_id[0])\n",
        "print(\"one hot:\", one_hot_id[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heZdN5dKZA9E"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_ckpt=\"distilbert-base-uncased\"\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRa5ggEPcz1F"
      },
      "outputs": [],
      "source": [
        "encoded_text=tokenizer(text)\n",
        "encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfyWBEbdc_hv"
      },
      "outputs": [],
      "source": [
        "tokens=tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmNt8hdoeE66"
      },
      "outputs": [],
      "source": [
        "sentence=tokenizer.convert_tokens_to_string(tokens)\n",
        "sentence[6:-6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATnFpC4nfb-u"
      },
      "outputs": [],
      "source": [
        "def tokenize(batch):\n",
        " return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EISXDK2Ef-ud"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOPmaIdgqA3o"
      },
      "outputs": [],
      "source": [
        "model_ckpt='distilbert-base-uncased'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HKL50qGqK4N"
      },
      "outputs": [],
      "source": [
        "model=AutoModel.from_pretrained(model_ckpt).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxPBUweEqTI0"
      },
      "outputs": [],
      "source": [
        "text=\"we are learing to use pretrained models\"\n",
        "\n",
        "inputs=tokenizer(text,return_tensors='pt')\n",
        "\n",
        "inputs['input_ids'].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-kJBgU4q4Zh"
      },
      "outputs": [],
      "source": [
        "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
        "with torch.no_grad():\n",
        " outputs = model(**inputs)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jngH45AZyMJ8"
      },
      "outputs": [],
      "source": [
        "outputs.last_hidden_state.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACwmPBHwylqy"
      },
      "outputs": [],
      "source": [
        "def extract_hidden_states(batch):\n",
        " # Place model inputs on the GPU\n",
        " inputs = {k:v.to(device) for k,v in batch.items()if k in tokenizer.model_input_names}\n",
        " # Extract last hidden states\n",
        " with torch.no_grad():\n",
        "  last_hidden_state = model(**inputs).last_hidden_state\n",
        " # Return vector for [CLS] token\n",
        " return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b65d5506"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "emotions = load_dataset('emotion')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvZArrioz20U"
      },
      "outputs": [],
      "source": [
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\n",
        "emotions_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQtFmBtez4tu"
      },
      "outputs": [],
      "source": [
        "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_CdKoLd0a78"
      },
      "outputs": [],
      "source": [
        "emotions_hidden_state=emotions_encoded.map(extract_hidden_states,batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "medHJ-8Y-FOM"
      },
      "outputs": [],
      "source": [
        "emotions_hidden_state[\"train\"].column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks_7hxp8CI54"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piQez4-wAJ4D"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(emotions_hidden_state[\"train\"][\"hidden_state\"])\n",
        "X_valid = np.array(emotions_hidden_state[\"validation\"][\"hidden_state\"])\n",
        "y_train = np.array(emotions_hidden_state[\"train\"][\"label\"])\n",
        "y_valid = np.array(emotions_hidden_state[\"validation\"][\"label\"])\n",
        "X_train.shape, X_valid.shape\n",
        "((16000, 768), (2000, 768))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X-OO9UYHWOc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiAQk88CCK2G"
      },
      "outputs": [],
      "source": [
        "from umap import UMAP\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
        "\n",
        "mapper = UMAP(n_components=2, metric=\"cosine\").fit(X_scaled)\n",
        "\n",
        "df_emb = pd.DataFrame(mapper.embedding_, columns=[\"X\", \"Y\"])\n",
        "df_emb[\"label\"] = y_train\n",
        "df_emb.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2Ai4KqaGXqw"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(7,5))\n",
        "axes = axes.flatten()\n",
        "cmaps = [\"Greys\", \"Blues\", \"Oranges\", \"Reds\", \"Purples\", \"Greens\"]\n",
        "labels = emotions[\"train\"].features[\"label\"].names\n",
        "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
        " df_emb_sub = df_emb.query(f\"label == {i}\")\n",
        " axes[i].hexbin(df_emb_sub[\"X\"], df_emb_sub[\"Y\"], cmap=cmap,\n",
        " gridsize=20, linewidths=(0,))\n",
        " axes[i].set_title(label)\n",
        " axes[i].set_xticks([]), axes[i].set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xNevispHUel",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression(max_iter=3000)\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_clf.score(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meHnKA1RRM_e"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcJFKsumvsGR"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier()\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "dummy_clf.score(X_valid, y_valid)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels=6\n",
        "model=AutoModelForSequenceClassification.from_pretrained(model_ckpt,num_labels=num_labels).to(device)"
      ],
      "metadata": {
        "id": "spqLs3ekFnJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining performance metrics"
      ],
      "metadata": {
        "id": "7XLeAMQPGsVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\"accuracy\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "id": "GUszgB3BGk9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "xCVi7-i_KfC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "batch_size = 64\n",
        "logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        " num_train_epochs=2,\n",
        "learning_rate=2e-5,\n",
        "per_device_train_batch_size=batch_size,\n",
        "per_device_eval_batch_size=batch_size,\n",
        "weight_decay=0.01,\n",
        "eval_strategy=\"epoch\",\n",
        " disable_tqdm=False,\n",
        " logging_steps=logging_steps,\n",
        " push_to_hub=True,\n",
        "log_level=\"error\")"
      ],
      "metadata": {
        "id": "V960nnOaLvoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "trainer = Trainer(model=model, args=training_args, compute_metrics=compute_metrics, train_dataset=emotions_encoded[\"train\"], eval_dataset=emotions_encoded[\"validation\"], tokenizer=tokenizer)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "XWcSVrbw8jFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(commit_message=\"Training completed!\")"
      ],
      "metadata": {
        "id": "Wb-_-o9iMnLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "model_id= \"Aditya161205/distilbert-base-uncased-finetuned-emotion\"\n",
        "classifier = pipeline(\"text-classification\", model=model_id)"
      ],
      "metadata": {
        "id": "mbnvUyGI1FiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom= \"i didnt expected this from the movie\"\n",
        "preds= classifier(custom, return_all_scores=True)\n",
        "preds"
      ],
      "metadata": {
        "id": "F1LJ60WiXhgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "UHVi70102KEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(preds[0])\n",
        "df['label'] = df['label'].apply(lambda x: labels[int(x.split('_')[1])])\n",
        "df"
      ],
      "metadata": {
        "id": "iAy8iN613UZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(preds[0])\n",
        "plt.bar(labels,100*df[\"score\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "si1so3vx1pYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfKKncbc2ExK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}