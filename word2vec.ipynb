{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPj8yr/tyStiQ0gtWAooBh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya161205/NLP/blob/main/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Coding a word2vec encoder**"
      ],
      "metadata": {
        "id": "PzglONyiDOLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "work flow:\n",
        "\n",
        "*   Import the libraries and create a sample corpus\n",
        "*   Create Tokenizer function\n",
        "*   creating vocab\n",
        "*   creating word2idx, idx2word\n",
        "*   doing one_hot_encoding\n",
        "*   generating skip gram pairs\n",
        "*   initializing the model\n",
        "*   coding forward pass\n",
        "*   backpropogation\n",
        "*   training loop\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "77-XGt75DSWt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "cT48v8t1DLDh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"This is my word to vector code.\""
      ],
      "metadata": {
        "id": "3MWA_LHtDpcK"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(corpus):\n",
        "  corpus=corpus.lower()\n",
        "  corpus=re.sub(r'[^\\w\\s]',\"\",corpus)\n",
        "  tokens=corpus.split()\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "dY82air-EK4z"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=tokenizer(corpus)\n",
        "vocab=set(tokens)\n",
        "print(vocab)\n",
        "\n",
        "n=len(vocab)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmHr50l_FIqR",
        "outputId": "5e89d37e-c50f-4d95-c7cd-1a9ef347f4d3"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'to', 'code', 'my', 'vector', 'word', 'is', 'this'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx={}\n",
        "\n",
        "for i,word in enumerate(vocab):\n",
        "  word2idx[word]=i\n",
        "\n",
        "print(word2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEjBI-jkFb-c",
        "outputId": "46e8da85-2f2c-49c0-8dd7-26d52d380355"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'to': 0, 'code': 1, 'my': 2, 'vector': 3, 'word': 4, 'is': 5, 'this': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2word={}\n",
        "for idx,word in enumerate(vocab):\n",
        "  idx2word[idx]=word\n",
        "\n",
        "print(idx2word)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1E9Zb_-HxK7",
        "outputId": "5d12294d-279d-42c4-b1c4-83603a894705"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'to', 1: 'code', 2: 'my', 3: 'vector', 4: 'word', 5: 'is', 6: 'this'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(word):\n",
        "  vec=np.zeros(n)\n",
        "  vec[word2idx[word]]=1\n",
        "  return vec\n",
        "\n",
        "print(one_hot_encoding(\"code\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGaAAJfTH79C",
        "outputId": "fda26246-4279-43f1-e53b-270a87a05473"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating skip gram pairs"
      ],
      "metadata": {
        "id": "exjGOVA7HREt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_skip_gram_pairs(tokens,window_size=2):\n",
        "  pairs=[]\n",
        "  for i,center in enumerate(tokens):\n",
        "    for j in range(max(0,i-window_size),min(n,i+window_size)):\n",
        "      if(j!=i):\n",
        "        pairs.append((center,tokens[j]))\n",
        "  return pairs\n",
        "pairs=generate_skip_gram_pairs(tokens)\n",
        "print(pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTkZdw8sJmev",
        "outputId": "7bfa630b-dd99-49c0-c885-579062f08dd5"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('this', 'is'), ('is', 'this'), ('is', 'my'), ('my', 'this'), ('my', 'is'), ('my', 'word'), ('word', 'is'), ('word', 'my'), ('word', 'to'), ('to', 'my'), ('to', 'word'), ('to', 'vector'), ('vector', 'word'), ('vector', 'to'), ('vector', 'code'), ('code', 'to'), ('code', 'vector')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=7\n",
        "\n",
        "W1=np.random.rand(n,embedding_dim)\n",
        "W2=np.random.rand(embedding_dim,n)"
      ],
      "metadata": {
        "id": "FwBfou4rIU5L"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  e_x=np.exp(x-max(x))\n",
        "  return e_x/np.sum(e_x,axis=0)\n",
        "\n",
        "def forward(x):\n",
        "  h=np.dot(W1.T,x)\n",
        "  u=np.dot(W2.T,h)\n",
        "\n",
        "  return softmax(u),h\n"
      ],
      "metadata": {
        "id": "FMe-ckYMKOJ5"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(y_pred, y_true):\n",
        "    return -np.sum(y_true * np.log(y_pred + 1e-8))"
      ],
      "metadata": {
        "id": "1FPNV_yHPUcX"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backprop(x,h,y_pred,y_true,lr=0.01):\n",
        "  global W1,W2\n",
        "  loss=cross_entropy(y_pred,y_true)\n",
        "  error=y_pred-y_true\n",
        "\n",
        "  dW2=np.outer(h,error)\n",
        "  dW1=np.outer(x,np.dot(W2,error))\n",
        "\n",
        "\n",
        "  W1-=lr*dW1\n",
        "  W2-=lr*dW2"
      ],
      "metadata": {
        "id": "En0vet2ZOhD8"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss = 0\n",
        "    for center, context in pairs:\n",
        "        x = one_hot_encoding(center)\n",
        "        y_true = one_hot_encoding(context)\n",
        "\n",
        "        y_pred, h = forward(x)\n",
        "        loss += cross_entropy(y_pred, y_true)\n",
        "        backprop(x, h, y_pred, y_true)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRi2y5K0ROvj",
        "outputId": "192c7317-5ae4-43f9-a4ec-db28026001d5"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 34.3848\n",
            "Epoch 100, Loss: 22.8281\n",
            "Epoch 200, Loss: 18.0605\n",
            "Epoch 300, Loss: 17.2028\n",
            "Epoch 400, Loss: 16.9658\n",
            "Epoch 500, Loss: 16.8733\n",
            "Epoch 600, Loss: 16.8298\n",
            "Epoch 700, Loss: 16.8070\n",
            "Epoch 800, Loss: 16.7942\n",
            "Epoch 900, Loss: 16.7866\n",
            "Epoch 1000, Loss: 16.7819\n",
            "Epoch 1100, Loss: 16.7789\n",
            "Epoch 1200, Loss: 16.7769\n",
            "Epoch 1300, Loss: 16.7755\n",
            "Epoch 1400, Loss: 16.7744\n",
            "Epoch 1500, Loss: 16.7736\n",
            "Epoch 1600, Loss: 16.7729\n",
            "Epoch 1700, Loss: 16.7722\n",
            "Epoch 1800, Loss: 16.7715\n",
            "Epoch 1900, Loss: 16.7709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(word):\n",
        "    return W1[word2idx[word]]\n"
      ],
      "metadata": {
        "id": "QiW_49TDR3Ye"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_embedding(\"code\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd8rViaoTaOW",
        "outputId": "0b6756ac-8e82-4382-bbfa-d51aebd802ff"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.92162586,  1.72369766,  0.30251172,  0.98986981, -0.71815806,\n",
              "        0.88116023, -1.31081949])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    }
  ]
}